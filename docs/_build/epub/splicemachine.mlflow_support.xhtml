<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>splicemachine.mlflow_support package</title>
    <link rel="stylesheet" href="_static/epub.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> 
  </head><body>

    <div class="document">
      <div class="documentwrapper">
          <div class="body" role="main">
            
  <div class="section" id="splicemachine-mlflow-support-package">
<h1>splicemachine.mlflow_support package</h1>
<div class="section" id="submodules">
<h2>Submodules</h2>
</div>
<div class="section" id="module-splicemachine.mlflow_support.constants">
<span id="splicemachine-mlflow-support-constants-module"></span><h2>splicemachine.mlflow_support.constants module</h2>
</div>
<div class="section" id="module-splicemachine.mlflow_support.mlflow_support">
<span id="splicemachine-mlflow-support-mlflow-support-module"></span><h2>splicemachine.mlflow_support.mlflow_support module</h2>
<p>Copyright 2020 Splice Machine, Inc.</p>
<p>Licensed under the Apache License, Version 2.0 (the “License”);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at</p>
<blockquote>
<div><p><a class="reference external" href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></p>
</div></blockquote>
<p>Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an “AS IS” BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.</p>
<hr class="docutils" />
<p>All functions in this module are accessible through the mlflow object and are to be referenced without the leading underscore as</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">function_name</span><span class="p">()</span>
</pre></div>
</div>
<p>For example, the function _current_exp_id() is accessible via</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">current_exp_id</span><span class="p">()</span>
</pre></div>
</div>
<p>All functions are accessible after running the following import</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">splicemachine.mlflow_support</span> <span class="kn">import</span> <span class="o">*</span>
</pre></div>
</div>
<p>Importing anything directly from mlflow before running the above statement will cause problems. After running the above import, you can import additional mlflow submodules as normal</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">splicemachine.mlflow_support</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">mlflow.tensorflow</span> <span class="kn">import</span> <span class="n">autolog</span>
</pre></div>
</div>
<hr class="docutils" />
<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._current_exp_id">
<code class="sig-name descname">_current_exp_id</code><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Retrieve the current exp id</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(int) the current experiment id</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._current_run_id">
<code class="sig-name descname">_current_run_id</code><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Retrieve the current run id</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(str) the current run id</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._deploy_aws">
<code class="sig-name descname">_deploy_aws</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">app_name</span></em>, <em class="sig-param"><span class="n">region</span><span class="o">=</span><span class="default_value">'us-east-2'</span></em>, <em class="sig-param"><span class="n">instance_type</span><span class="o">=</span><span class="default_value">'ml.m5.xlarge'</span></em>, <em class="sig-param"><span class="n">run_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">instance_count</span><span class="o">=</span><span class="default_value">1</span></em>, <em class="sig-param"><span class="n">deployment_mode</span><span class="o">=</span><span class="default_value">'replace'</span></em><span class="sig-paren">)</span></dt>
<dd><p>Queue Job to deploy a run to sagemaker with the
given run id (found in MLFlow UI or through search API)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>run_id</strong> – the id of the run to deploy. Will default to the current
run id.</p></li>
<li><p><strong>app_name</strong> – the name of the app in sagemaker once deployed</p></li>
<li><p><strong>region</strong> – the sagemaker region to deploy to (us-east-2,
us-west-1, us-west-2, eu-central-1 supported)</p></li>
<li><p><strong>instance_type</strong> – the EC2 Sagemaker instance type to deploy on
(ml.m4.xlarge supported)</p></li>
<li><p><strong>instance_count</strong> – the number of instances to load balance predictions
on</p></li>
<li><p><strong>deployment_mode</strong> – the method to deploy; create=application will fail
if an app with the name specified already exists; replace=application
in sagemaker will be replaced with this one if app already exists;
add=add the specified model to a prexisting application (not recommended)</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._deploy_azure">
<code class="sig-name descname">_deploy_azure</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">endpoint_name</span></em>, <em class="sig-param"><span class="n">resource_group</span></em>, <em class="sig-param"><span class="n">workspace</span></em>, <em class="sig-param"><span class="n">run_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">region</span><span class="o">=</span><span class="default_value">'East US'</span></em>, <em class="sig-param"><span class="n">cpu_cores</span><span class="o">=</span><span class="default_value">0.1</span></em>, <em class="sig-param"><span class="n">allocated_ram</span><span class="o">=</span><span class="default_value">0.5</span></em>, <em class="sig-param"><span class="n">model_name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Deploy a given run to AzureML.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>endpoint_name</strong> – (str) the name of the endpoint in AzureML when deployed to
Azure Container Services. Must be unique.</p></li>
<li><p><strong>resource_group</strong> – (str) Azure Resource Group for model. Automatically created if
it doesn’t exist.</p></li>
<li><p><strong>workspace</strong> – (str) the AzureML workspace to deploy the model under.
Will be created if it doesn’t exist</p></li>
<li><p><strong>run_id</strong> – (str) if specified, will deploy a previous run (
must have an spark model logged). Otherwise, will default to the active run</p></li>
<li><p><strong>region</strong> – (str) AzureML Region to deploy to: Can be East US, East US 2, Central US,
West US 2, North Europe, West Europe or Japan East</p></li>
<li><p><strong>cpu_cores</strong> – (float) Number of CPU Cores to allocate to the instance.
Can be fractional. Default=0.1</p></li>
<li><p><strong>allocated_ram</strong> – (float) amount of RAM, in GB, allocated to the container.
Default=0.5</p></li>
<li><p><strong>model_name</strong> – (str) If specified, this will be the name of the model in AzureML.
Otherwise, the model name will be randomly generated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._deploy_db">
<code class="sig-name descname">_deploy_db</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">db_schema_name</span></em>, <em class="sig-param"><span class="n">db_table_name</span></em>, <em class="sig-param"><span class="n">run_id</span></em>, <em class="sig-param"><span class="n">primary_key</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">df</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">create_model_table</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">model_cols</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">classes</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">sklearn_args</span><span class="o">=</span><span class="default_value">{}</span></em>, <em class="sig-param"><span class="n">verbose</span><span class="o">=</span><span class="default_value">False</span></em>, <em class="sig-param"><span class="n">pred_threshold</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">replace</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span> &#x2192; None</dt>
<dd><p>Deploy a trained (currently Spark, Sklearn, Keras or H2O) model to the Database.
This either creates a new table or alters an existing table in the database (depending on parameters passed)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>db_schema_name</strong> – (str) the schema name to deploy to.</p></li>
<li><p><strong>db_table_name</strong> – (str) the table name to deploy to.</p></li>
<li><p><strong>run_id</strong> – (str) The run_id to deploy the model on. The model associated with this run will be deployed</p></li>
<li><p><strong>primary_key</strong> – <p>(List[Tuple[str, str]]) List of column + SQL datatype to use for the primary/composite key.</p>
<ul>
<li><p>If you are deploying to a table that already exists, it must already have a primary key, and this parameter will be ignored.</p></li>
<li><p>If you are creating the table in this function, you MUST pass in a primary key</p></li>
</ul>
</p></li>
<li><p><strong>df</strong> – <p>(Spark or Pandas DF) The dataframe used to train the model</p>
<div class="line-block">
<div class="line">NOTE: The columns in this df are the ones that will be used to create the table unless specified by model_cols</div>
</div>
</p></li>
<li><p><strong>create_model_table</strong> – Whether or not to create the table from the dataframe. Default false. This
Will ONLY be used if the table does not exist and a dataframe is passed in</p></li>
<li><p><strong>model_cols</strong> – (List[str]) The columns from the table to use for the model. If None, all columns in the table
will be passed to the model. If specified, the columns will be passed to the model
IN THAT ORDER. The columns passed here must exist in the table.</p></li>
<li><p><strong>classes</strong> – <p>(List[str]) The classes (prediction labels) for the model being deployed.</p>
<p>NOTE: If not supplied, the table will have default column names for each class</p>
</p></li>
<li><p><strong>sklearn_args</strong> – <p>(dict{str: str}) Prediction options for sklearn models:</p>
<ul>
<li><p>Available key value options:</p>
<blockquote>
<div><ul>
<li><p>’predict_call’: ‘predict’, ‘predict_proba’, or ‘transform’</p>
<blockquote>
<div><ul>
<li><p>Determines the function call for the model</p>
<blockquote>
<div><ul class="simple">
<li><p>If blank, predict will be used (or transform if model doesn’t have predict)</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
<li><p>’predict_args’: ‘return_std’ or ‘return_cov’ - For Bayesian and Gaussian models</p>
<blockquote>
<div><ul>
<li><p>Only one can be specified</p>
<blockquote>
<div><ul class="simple">
<li><p>If the model does not have the option specified, it will be ignored.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
</li>
</ul>
</p></li>
<li><p><strong>verbose</strong> – (bool) Whether or not to print out the queries being created. Helpful for debugging</p></li>
<li><p><strong>pred_threshold</strong> – <p>(double) A prediction threshold for <em>Keras</em> binary classification models</p>
<ul>
<li><p>If the model type isn’t Keras, this parameter will be ignored</p></li>
</ul>
<p>NOTE: If the model type is Keras, the output layer has 1 node, and pred_threshold is None,                 you will NOT receive a class prediction, only the output of the final layer (like model.predict()).                 If you want a class prediction                 for your binary classification problem, you MUST pass in a threshold.</p>
</p></li>
<li><p><strong>replace</strong> – (bool) whether or not to replace a currently existing model. This param does not yet work</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
<p>This function creates the following IF you are creating a table from the dataframe</p>
<blockquote>
<div><ul>
<li><p>The model table where run_id is the run_id passed in. This table will have a column for each feature in the feature vector. It will also contain:</p>
<blockquote>
<div><ul class="simple">
<li><p>USER which is the current user who made the request</p></li>
<li><p>EVAL_TIME which is the CURRENT_TIMESTAMP</p></li>
<li><p>the PRIMARY KEY column(s) passed in</p></li>
<li><p>PREDICTION. The prediction of the model. If the :classes: param is not filled in, this will be default values for classification models</p></li>
<li><p>A column for each class of the predictor with the value being the probability/confidence of the model if applicable</p></li>
</ul>
</div></blockquote>
</li>
</ul>
</div></blockquote>
<p>IF you are deploying to an existing table, the table will be altered to include the columns above.</p>
<dl class="field-list">
<dt class="field-odd">NOTE</dt>
<dd class="field-odd"><div class="highlight-text notranslate"><div class="highlight"><pre><span></span>The columns listed above are default value columns.

This means that on a SQL insert into the table, 

you do not need to reference or insert values into them.

They are automatically taken care of.

Set verbose=True in the function call for more information
</pre></div>
</div>
</dd>
</dl>
<p>The following will also be created for all deployments:</p>
<blockquote>
<div><ul class="simple">
<li><p>A trigger that runs on (after) insertion to the data table that runs an INSERT into the prediction table,             calling the PREDICT function, passing in the row of data as well as the schema of the dataset, and the run_id of the model to run</p></li>
<li><p>A trigger that runs on (after) insertion to the prediction table that calls an UPDATE to the row inserted,             parsing the prediction probabilities and filling in proper column values</p></li>
</ul>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._download_artifact">
<code class="sig-name descname">_download_artifact</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">name</span></em>, <em class="sig-param"><span class="n">local_path</span></em>, <em class="sig-param"><span class="n">run_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Download the artifact at the given run id (active default) + name to the local path</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> – (str) artifact name to load (with respect to the run)</p></li>
<li><p><strong>local_path</strong> – (str) local path to download the model to. This path MUST include the file extension</p></li>
<li><p><strong>run_id</strong> – (str) the run id to download the artifact from. Defaults to active run</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._get_current_run_data">
<code class="sig-name descname">_get_current_run_data</code><span class="sig-paren">(</span><span class="sig-paren">)</span></dt>
<dd><p>Get the data associated with the current run.
As of MLFLow 1.6, it currently does not support getting run info from the mlflow.active_run object, so we need it
to be retrieved via the tracking client.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>active run data object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._get_deployed_models">
<code class="sig-name descname">_get_deployed_models</code><span class="sig-paren">(</span><span class="sig-paren">)</span> &#x2192; pandas.core.frame.DataFrame</dt>
<dd><p>Get the currently deployed models in the database
:return: Pandas df</p>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._get_model_name">
<code class="sig-name descname">_get_model_name</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">run_id</span></em><span class="sig-paren">)</span></dt>
<dd><p>Gets the model name associated with a run or None</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>run_id</strong> – (str) the run_id that the model is stored under</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(str or None) The model name if it exists</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._get_run_ids_by_name">
<code class="sig-name descname">_get_run_ids_by_name</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">run_name</span></em>, <em class="sig-param"><span class="n">experiment_id</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Gets a run id from the run name. If there are multiple runs with the same name, all run IDs are returned</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>run_name</strong> – (str) The name of the run</p></li>
<li><p><strong>experiment_id</strong> – (int) The experiment to search in. If None, all experiments are searched. [Default None]</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(List[str]) List of run ids</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._initiate_job">
<code class="sig-name descname">_initiate_job</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">payload</span></em>, <em class="sig-param"><span class="n">endpoint</span></em><span class="sig-paren">)</span></dt>
<dd><p>Send a job to the initiation endpoint</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>payload</strong> – (dict) JSON payload for POST request</p></li>
<li><p><strong>endpoint</strong> – (str) REST endpoint to target</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>(str) Response text from request</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._lm">
<code class="sig-name descname">_lm</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">key</span></em>, <em class="sig-param"><span class="n">value</span></em>, <em class="sig-param"><span class="n">step</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Add a shortcut for logging metrics in MLFlow.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> – (str) key for the parameter</p></li>
<li><p><strong>value</strong> – (str or int) value for the parameter</p></li>
<li><p><strong>step</strong> – (int) A single integer step at which to log the specified Metrics. If unspecified, each metric is logged at step zero.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._load_model">
<code class="sig-name descname">_load_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">run_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Download and deserialize a serialized model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>run_id</strong> – the id of the run to get a model from
(the run must have an associated model with it named spark_model)</p></li>
<li><p><strong>name</strong> – the name of the model in the database</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._log_artifact">
<code class="sig-name descname">_log_artifact</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">file_name</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">run_uuid</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span></dt>
<dd><p>Log an artifact for the active run</p>
<dl class="field-list">
<dt class="field-odd">Example</dt>
<dd class="field-odd"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>

    <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="s1">&#39;my_image.png&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>file_name</strong> – (str) the name of the file name to log</p></li>
<li><p><strong>name</strong> – (str) the name of the run relative name to store the model under</p></li>
<li><p><strong>run_uuid</strong> – (str) the run uuid of a previous run, if none, defaults to current run</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
<dt class="field-even">NOTE</dt>
<dd class="field-even"><p>We do not currently support logging directories. If you would like to log a directory, please zip it first and log the zip file</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._log_feature_transformations">
<code class="sig-name descname">_log_feature_transformations</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">unfit_pipeline</span></em><span class="sig-paren">)</span></dt>
<dd><p>Log feature transformations for an unfit spark pipeline
Logs –&gt; feature movement through the pipeline</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>unfit_pipeline</strong> – (PipelineModel) unfit spark pipeline to log</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._log_model">
<code class="sig-name descname">_log_model</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">model</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">'model'</span></em><span class="sig-paren">)</span></dt>
<dd><p>Log a trained machine learning model</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> – (Model) is the trained Spark/SKlearn/H2O/Keras model
with the current run</p></li>
<li><p><strong>name</strong> – (str) the run relative name to store the model under. [Deault ‘model’]</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._log_model_params">
<code class="sig-name descname">_log_model_params</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pipeline_or_model</span></em><span class="sig-paren">)</span></dt>
<dd><p>Log the parameters of a fitted spark model or a model stage of a fitted spark pipeline</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pipeline_or_model</strong> – fitted spark pipeline/fitted spark model</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._log_pipeline_stages">
<code class="sig-name descname">_log_pipeline_stages</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">pipeline</span></em><span class="sig-paren">)</span></dt>
<dd><p>Log the pipeline stages of a Spark Pipeline as params for the run</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>pipeline</strong> – (PipelineModel) fitted/unitted pipeline</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._login_director">
<code class="sig-name descname">_login_director</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">username</span></em>, <em class="sig-param"><span class="n">password</span></em><span class="sig-paren">)</span></dt>
<dd><p>Authenticate into the MLManager Director</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>username</strong> – (str) database username</p></li>
<li><p><strong>password</strong> – (str) database password</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._lp">
<code class="sig-name descname">_lp</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">key</span></em>, <em class="sig-param"><span class="n">value</span></em><span class="sig-paren">)</span></dt>
<dd><p>Add a shortcut for logging parameters in MLFlow.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> – (str) key for the parameter</p></li>
<li><p><strong>value</strong> – (str) value for the parameter</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._mlflow_patch">
<code class="sig-name descname">_mlflow_patch</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">name</span></em><span class="sig-paren">)</span></dt>
<dd><p>Create a MLFlow Patch that applies the default gorilla settings</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>name</strong> – destination name under mlflow package</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>decorator for patched function</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._register_splice_context">
<code class="sig-name descname">_register_splice_context</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">splice_context</span></em><span class="sig-paren">)</span></dt>
<dd><p>Register a Splice Context for Spark/Database operations (artifact storage, for example)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>splice_context</strong> – (PySpliceContext) splice context to input</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._start_run">
<code class="sig-name descname">_start_run</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">run_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">tags</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">experiment_id</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">run_name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">nested</span><span class="o">=</span><span class="default_value">False</span></em><span class="sig-paren">)</span></dt>
<dd><p>Start a new run</p>
<dl class="field-list">
<dt class="field-odd">Example</dt>
<dd class="field-odd"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s1">&#39;my_run&#39;</span><span class="p">)</span>

<span class="c1"># or</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span><span class="n">run_name</span><span class="o">=</span><span class="s1">&#39;my_run&#39;</span><span class="p">):</span>
    <span class="o">...</span>
</pre></div>
</div>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>tags</strong> – a dictionary containing metadata about the current run.         For example:             {                 ‘team’: ‘pd’,                 ‘purpose’: ‘r&amp;d’             }</p></li>
<li><p><strong>run_name</strong> – (str) an optional name for the run to show up in the MLFlow UI. [Default None]</p></li>
<li><p><strong>run_id</strong> – (str) if you want to reincarnate an existing run, pass in the run id [Default None]</p></li>
<li><p><strong>experiment_id</strong> – (int) if you would like to create an experiment/use one for this run [Default None]</p></li>
<li><p><strong>nested</strong> – (bool) Controls whether run is nested in parent run. True creates a nest run [Default False]</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>(ActiveRun) the mlflow active run object</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support._timer">
<code class="sig-name descname">_timer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">timer_name</span></em>, <em class="sig-param"><span class="n">param</span><span class="o">=</span><span class="default_value">True</span></em><span class="sig-paren">)</span></dt>
<dd><p>Context manager for logging</p>
<dl class="field-list">
<dt class="field-odd">Example</dt>
<dd class="field-odd"><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">timer</span><span class="p">(</span><span class="s1">&#39;my_timer&#39;</span><span class="p">):</span> 

    <span class="o">...</span>
</pre></div>
</div>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><ul class="simple">
<li><p><strong>timer_name</strong> – (str) the name of the timer</p></li>
<li><p><strong>param</strong> – (bool) whether or not to log the timer as a param (default=True). If false, logs as metric.</p></li>
</ul>
</dd>
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>None</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="splicemachine.mlflow_support.mlflow_support.set_mlflow_uri">
<code class="sig-name descname">set_mlflow_uri</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">uri</span></em><span class="sig-paren">)</span></dt>
<dd><p>Set the tracking uri for mlflow. Only needed if running outside of the Splice Machine K8s Cloud Service</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>uri</strong> – (str) the URL of your mlflow UI.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>None</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="module-splicemachine.mlflow_support.utilities">
<span id="splicemachine-mlflow-support-utilities-module"></span><h2>splicemachine.mlflow_support.utilities module</h2>
</div>
<div class="section" id="module-splicemachine.mlflow_support">
<span id="module-contents"></span><h2>Module contents</h2>
</div>
</div>


            <div class="clearer"></div>
          </div>
      </div>
      <div class="clearer"></div>
    </div>
  </body>
</html>